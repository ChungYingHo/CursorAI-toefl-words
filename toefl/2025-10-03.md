---
date: 2025/10/03
title: The people turning to AI for dating and relationship advice
link: https://www.bbc.com/news/articles/c0kn4e377e2o
---

Earlier this year, Rachel wanted to `clear the air` with a man she had been dating before seeing him again in a `wider` friendship group setting. "I'd used ChatGPT for job searching but had heard someone else use it for dating advice," says Rachel, who does not want her real name used, and lives in Sheffield. "I was feeling quite `distressed` and wanted `guidance`, and didn't want friends `involved`." Before the phone call, she turned to ChatGPT for help. "I asked, how do I deal with this conversation but not be on the defensive." Its response? "ChatGPT does this all the time but it was something like 'wow, that's such a `self-aware` question, you must be emotionally `mature` going through this. Here are some tips'. It was like a cheerleader on my side, like I was right and he was wrong." Overall, she says it was "useful" but described the language as "very much like `therapy` speak, using words like '`boundaries`'". "All I took from it was it reminded me to be OK to do it on my terms, but I didn't take it too `literally`."  

Rachel is not alone in turning to AI for advice in dealing with relationships. According to research by the online dating `firm` Match, almost half of Generation Z Americans (those born between 1997 and 2012) said they have used LLMs like ChatGPT for dating advice, that's more than any other generation. People are turning to AI to help `craft` `breakup` messages, to `dissect` conversations they're having with people they're dating, and to resolve problems in relationships.  

Dr Lalitaa Suglani, psychologist and relationship `expert`, says AI can be a useful tool, especially for people who feel `overwhelmed` or `unsure` when it comes to communication in relationships. It may help them to `craft` a text, `process` a confusing message or `source` a second opinion, which can offer a moment of pause instead of being reactive, she says. "In many ways it can `function like` a journalling prompt or `reflective` space, which can be supportive when used as a tool and not a replacement for connection," says Dr Suglani. However, she flags several concerns. "LLMs are trained to be helpful and agreeable and repeat back what you are sharing, so they may `subtly` `validate` `dysfunctional` patterns or `echo back` `assumptions`, especially if the prompt is `biased` and the problem with this it can `reinforce` `distorted` `narratives` or `avoidance` `tendencies`." For example, she says, using AI to write a breakup text might be a way to avoid the discomfort of the situation. That might contribute to avoidant behaviours, as the individual is not sitting with how they actually feel. Using AI might also inhibit their own development. "If someone turns to an LLM every time they're unsure how to respond or feel emotionally exposed, they might start `outsourcing` their `intuition`, emotional language, and sense of `relational self`," says Dr Suglani. She also notes that AI messages can be emotionally `sterile` and make communication feel `scripted`, which can be `unnerving` to `receive`.  

Despite the challenges, services are `springing up` to serve the market for relationship advice. Mei is a free AI generated service. Trained using Open AI, the service responds to relationship `dilemmas` with conversational-like responses. "The idea is to allow people to instantly `seek` help to navigate relationships because not everyone can talk to friends or family for fear of judgment," says New York-based `founder` Es Lee. He says more than half of the issues `brought up` on the AI tool concern sex, a subject that many may not wish to discuss with friends or a therapist, Mr Lee says. "People are only using AI as existing services are lacking," he says. Another common use is how to reword a message or how to fix an issue in a relationship. "It's like people need AI to validate it the problem." When giving relationship advice, issues of safety could `come up`. A human `counsellor` would know when to `intervene` and protect a client from a potentially harmful situation. Would a relationship app provide the same `guardrails`? Mr Lee `recognises` the concern over safety. "I think the `stakes` are higher with AI because it can connect with us on a personal level the way no other technology has." But he says Mei has "guardrails" built into the AI. "We welcome professionals and `organisations` to partner with us and take an active role in `molding` our AI products," he says.  

OpenAI the creator of ChatGPT says that its latest model has shown improvements in areas like avoiding unhealthy levels of emotional `reliance` and `sycophancy`. In a `statement` the company said: "People sometimes `turn to` ChatGPT in sensitive moments, so we want to make sure it responds `appropriately`, guided by experts. This includes directing people to professional help when appropriate, `strengthening` our `safeguards` in how our models respond to sensitive requests and `nudging` for breaks during long sessions." Another area of concern is privacy. Such apps could potentially collect very sensitive data, which could be `devastating` if `exposed` by hackers. Mr Lee says "at every fork in the road on how we handle user privacy, we choose the one that preserves privacy and collects only what we need to provide the best service." As part of that policy, he says that Mei does not ask for information that would identify an individual, other than an email address. Mr Lee also says conversations are saved `temporarily` for quality `assurance` but `discarded` after 30 days. "They are not currently saved `permanently` to any database."  

Some people are using AI in combination with a human therapist. When Corinne (not her real name) was looking to end a relationship late last year, she started to turn to ChatGPT for advice on how to `deal with` it. London-based Corinne says she was inspired to turn to AI after hearing her housemate talk positively about using it for dating advice, including how to break up with someone. She said she would ask it to respond to her questions in the same style as popular relationship expert Jillian Turecki or `holistic` psychologist Dr Nicole LePera, both very popular on social media. When she started dating again at the start of the year she turned to it again, again asking for advice in the style of her favourite relationship experts. "Around January I had been on a date with a guy and I didn't find him `physically` attractive but we get on really well so I asked it if it was worth going on another date. I knew they would say yes as I read their books but it was nice to have the advice `tailored` to my `scenario`." Corinne, who has a therapist, says the discussions with her therapist `delve` more into childhood than the questions she raises with ChatGPT over dating or relationship queries. She says that she treats AI advice with "a bit of distance". "I can imagine people ending relationships and perhaps having conversations they shouldn't be having yet with their partner as ChatGPT just repeats back what it thinks you want to hear. It's good in life's stressful moments. And when a friend isn't around. It calms me down."  

:::summary
這篇文章討論越來越多人在感情問題上求助 AI（特別是 ChatGPT），尤其是年輕一代。  

- 個案經驗  
Rachel 在與前約會對象談話前向 ChatGPT 求助，她說：「All I took from it was it reminded me to be OK to do it on my terms, but I didn't take it too literally.」  

- 趨勢  
根據交友平台 Match 的研究，「almost half of Generation Z Americans said they have used LLMs like ChatGPT for dating advice, that's more than any other generation.」  

- 專家觀點  
心理學家 Dr Lalitaa Suglani 指出，AI 可提供支持，「In many ways it can function like a journalling prompt or reflective space, which can be supportive when used as a tool and not a replacement for connection.」  
但她也警告，「they may subtly validate dysfunctional patterns or echo back assumptions... it can reinforce distorted narratives or avoidance tendencies.」  

- 新服務  
AI 諮詢工具 Mei 應運而生。創辦人 Es Lee 說：「The idea is to allow people to instantly seek help to navigate relationships because not everyone can talk to friends or family for fear of judgment.」  
不過他也承認風險，「I think the stakes are higher with AI because it can connect with us on a personal level the way no other technology has.」  

- 公司回應與隱私顧慮  
OpenAI 表示：「People sometimes turn to ChatGPT in sensitive moments, so we want to make sure it responds appropriately, guided by experts.」  
但同時也有隱私問題，如果被駭客入侵「it could be devastating if exposed by hackers.」  

- 另一個個案  
Corinne 曾在分手時用 ChatGPT 諮詢，並在新戀情中再次使用，她說：「It was nice to have the advice tailored to my scenario... It's good in life's stressful moments. And when a friend isn't around. It calms me down.」  

總結  
AI 在戀愛與人際中提供方便的支持，但存在情感空洞、隱私風險，以及可能強化不健康模式的隱憂。  
:::

| 單字 | 音標 | 詞性 | 中文 | 例句 |
|------|------|------|------|------|
| clear the air | /klɪr ðə er/ | phr. v. | 消除誤會 | Rachel wanted to clear the air with a man she had been dating. |
| wider | /ˈwaɪdər/ | adj. | 更廣泛的 | Before seeing him again in a wider friendship group setting. |
| distressed | /dɪˈstrest/ | adj. | 感到痛苦的 | "I was feeling quite distressed and wanted guidance." |
| guidance | /ˈɡaɪdns/ | n. | 指導；建議 | "I was feeling quite distressed and wanted guidance." |
| involved | /ɪnˈvɑːlvd/ | adj. | 牽涉其中的 | "I didn't want friends involved." |
| self-aware | /ˌself əˈwer/ | adj. | 自我覺察的 | "Wow, that's such a self-aware question." |
| mature | /məˈtʊr/ | adj. | 成熟的 | "You must be emotionally mature going through this." |
| therapy | /ˈθerəpi/ | n. | 療法；治療 | She described the language as "very much like therapy speak." |
| boundary | /ˈbaʊndri/ | n. | 界線；界限 | Using words like "boundaries". |
| literally | /ˈlɪtərəli/ | adv. | 照字面地；確實地 | "But I didn't take it too literally." |
| firm | /fɜːrm/ | n. | 公司 | According to research by the online dating firm Match. |
| craft | /kræft/ | v. | 精心製作 | People are turning to AI to help craft breakup messages. |
| breakup | /ˈbreɪkʌp/ | n. | 分手 | People are turning to AI to help craft breakup messages. |
| dissect | /daɪˈsekt/ | v. | 分析；解剖 | People use AI to dissect conversations they're having. |
| expert | /ˈekspɜːrt/ | n. | 專家 | Dr Lalitaa Suglani, psychologist and relationship expert. |
| overwhelmed | /ˌoʊvərˈwelmd/ | adj. | 不知所措的 | AI can be useful for people who feel overwhelmed. |
| unsure | /ʌnˈʃʊr/ | adj. | 不確定的 | Useful for people who feel overwhelmed or unsure. |
| process | /ˈprɑːses/ | v. | 處理；消化 | It may help them to process a confusing message. |
| source | /sɔːrs/ | v. | 尋找；獲得 | Or source a second opinion. |
| function like | /ˈfʌŋkʃn laɪk/ | phr. | 像…一樣運作 | "In many ways it can function like a journalling prompt." |
| reflective | /rɪˈflektɪv/ | adj. | 反思的 | "Or reflective space, which can be supportive." |
| subtly | /ˈsʌtli/ | adv. | 微妙地 | They may subtly validate dysfunctional patterns. |
| validate | /ˈvælɪdeɪt/ | v. | 證實；確認 | They may subtly validate dysfunctional patterns. |
| dysfunctional | /dɪsˈfʌŋkʃənl/ | adj. | 功能失調的 | They may validate dysfunctional patterns. |
| echo back | /ˈekoʊ bæk/ | phr. v. | 重複回應 | Or echo back assumptions. |
| assumption | /əˈsʌmpʃn/ | n. | 假設 | Or echo back assumptions. |
| biased | /ˈbaɪəst/ | adj. | 有偏見的 | Especially if the prompt is biased. |
| reinforce | /ˌriːɪnˈfɔːrs/ | v. | 強化 | It can reinforce distorted narratives. |
| distorted | /dɪˈstɔːrtɪd/ | adj. | 扭曲的 | Reinforce distorted narratives. |
| narrative | /ˈnærətɪv/ | n. | 敘事 | Reinforce distorted narratives. |
| avoidance | /əˈvɔɪdəns/ | n. | 迴避 | Avoidance tendencies. |
| tendency | /ˈtendənsi/ | n. | 傾向 | Avoidance tendencies. |
| outsource | /ˈaʊtsɔːrs/ | v. | 外包；依賴外部 | They might start outsourcing their intuition. |
| intuition | /ˌɪntuˈɪʃn/ | n. | 直覺 | They might start outsourcing their intuition. |
| relational self | /rɪˈleɪʃənl self/ | n. | 人際自我 | And sense of relational self. |
| sterile | /ˈsterəl/ | adj. | 缺乏感情的 | AI messages can be emotionally sterile. |
| scripted | /skrɪptɪd/ | adj. | 照稿子唸的 | AI messages can feel scripted. |
| unnerving | /ʌnˈnɜːrvɪŋ/ | adj. | 令人不安的 | Which can be unnerving to receive. |
| receive | /rɪˈsiːv/ | v. | 接收 | Which can be unnerving to receive. |
| spring up | /sprɪŋ ʌp/ | phr. v. | 湧現；突然出現 | Services are springing up to serve the market. |
| dilemma | /dɪˈlemə/ | n. | 困境 | The service responds to relationship dilemmas. |
| seek | /siːk/ | v. | 尋求 | The idea is to allow people to instantly seek help. |
| founder | /ˈfaʊndər/ | n. | 創辦人 | Says New York-based founder Es Lee. |
| brought up | /brɔːt ʌp/ | phr. v. | 提出 | More than half of the issues brought up on the AI tool concern sex. |
| come up | /kʌm ʌp/ | phr. v. | 出現；發生 | Issues of safety could come up. |
| counsellor | /ˈkaʊnsələr/ | n. | 輔導員；諮商師 | A human counsellor would know when to intervene. |
| intervene | /ˌɪntərˈviːn/ | v. | 干預 | A human counsellor would know when to intervene. |
| guardrails | /ˈɡɑːrdreɪlz/ | n. | 防護措施 | Would a relationship app provide the same guardrails? |
| recognise | /ˈrekəɡnaɪz/ | v. | 認識；承認 | Mr Lee recognises the concern over safety. |
| stake | /steɪk/ | n. | 利害關係；風險 | "I think the stakes are higher with AI..." |
| organisation | /ˌɔːrɡənəˈzeɪʃn/ | n. | 組織 | We welcome professionals and organisations to partner with us. |
| molding | /ˈmoʊldɪŋ/ | v. | 塑造 | Take an active role in molding our AI products. |
| reliance | /rɪˈlaɪəns/ | n. | 依賴 | Avoiding unhealthy levels of emotional reliance. |
| sycophancy | /ˈsɪkəfənsi/ | n. | 諂媚 | Avoiding unhealthy levels of emotional reliance and sycophancy. |
| statement | /ˈsteɪtmənt/ | n. | 聲明 | In a statement the company said... |
| turn to | /tɜːrn tuː/ | phr. v. | 求助於 | People sometimes turn to ChatGPT in sensitive moments. |
| appropriately | /əˈproʊpriətli/ | adv. | 適當地 | We want to make sure it responds appropriately. |
| strengthen | /ˈstreŋkθn/ | v. | 加強 | Strengthening our safeguards. |
| safeguard | /ˈseɪfɡɑːrd/ | n. | 保護措施 | Strengthening our safeguards. |
| nudge | /nʌdʒ/ | v. | 輕推；引導 | Nudging for breaks during long sessions. |
| devastating | /ˈdevəsteɪtɪŋ/ | adj. | 毀滅性的 | Which could be devastating if exposed by hackers. |
| expose | /ɪkˈspoʊz/ | v. | 暴露 | Which could be devastating if exposed by hackers. |
| temporarily | /ˌtempəˈrerəli/ | adv. | 暫時地 | Conversations are saved temporarily for quality assurance. |
| assurance | /əˈʃʊrəns/ | n. | 保證；確信 | Saved temporarily for quality assurance. |
| discard | /dɪsˈkɑːrd/ | v. | 丟棄 | Conversations are discarded after 30 days. |
| permanently | /ˈpɜːrmənəntli/ | adv. | 永久地 | They are not currently saved permanently. |
| deal with | /diːl wɪð/ | phr. v. | 處理 | She started to turn to ChatGPT for advice on how to deal with it. |
| holistic | /hoʊˈlɪstɪk/ | adj. | 整體的；全面的 | Holistic psychologist Dr Nicole LePera. |
| physically | /ˈfɪzɪkli/ | adv. | 身體上；外表上 | I didn't find him physically attractive. |
| tailored | /ˈteɪlərd/ | adj. | 量身訂做的 | It was nice to have the advice tailored to my scenario. |
| scenario | /səˈnærioʊ/ | n. | 情境 | It was nice to have the advice tailored to my scenario. |
| delve | /delv/ | v. | 鑽研；探究 | The discussions with her therapist delve more into childhood. |
